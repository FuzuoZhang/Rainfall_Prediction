{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datatrans(data, T):\n",
    "    n,p = data.shape\n",
    "    n_sample = n-T\n",
    "    newdata = np.zeros((n_sample,T,p))\n",
    "    target = np.zeros((n_sample,))\n",
    "    for i in range(n_sample):\n",
    "        newdata[i] = data.iloc[i:i+T]\n",
    "        target[i] = data.iloc[i+T,12]\n",
    "    return newdata, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value2class(y):\n",
    "    y[np.where((y>0)&(y<=1))]=1\n",
    "    y[np.where((y>1)&(y<=4))]=2\n",
    "    y[np.where(y>4)]=3\n",
    "    #y[np.where(y>16)]=4\n",
    "    return y.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, T):\n",
    "    data = pd.read_csv(path)\n",
    "    data = data.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "    N = data.shape[0]\n",
    "    n_train = round(N * 0.7)\n",
    "    n_valid = round(N * 0.2)\n",
    "    n_test = N - n_train - n_valid\n",
    "\n",
    "    train = data.iloc[:n_train]\n",
    "    valid = data.iloc[n_train:n_train + n_valid]\n",
    "    test = data.iloc[n_train + n_valid:]\n",
    "\n",
    "    X_train, y_train = datatrans(train, T)\n",
    "    X_valid, y_valid = datatrans(valid, T)\n",
    "    X_test, y_test = datatrans(test, T)\n",
    "\n",
    "     # 分类\n",
    "    y_train = value2class(y_train)\n",
    "    y_valid = value2class(y_valid)\n",
    "    y_test = value2class(y_test)\n",
    "    \n",
    "    return X_train, y_train, X_valid, y_valid, X_test, y_test\n",
    "\n",
    "\n",
    "def preprocess_xgboost(path, T):\n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test = load_data(path, T)\n",
    "    \n",
    "    #展开\n",
    "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_valid = X_valid.reshape(X_valid.shape[0],-1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "    # normalization\n",
    "    sr_X = StandardScaler()\n",
    "    sr_X = sr_X.fit(X_train)\n",
    "    X_train = sr_X.transform(X_train)\n",
    "    X_valid = sr_X.transform(X_valid)\n",
    "    X_test = sr_X.transform(X_test)\n",
    "\n",
    "    return X_train, y_train, X_valid, y_valid, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_classifier_train(params, X_train, y_train):\n",
    "    clf = xgb.XGBClassifier(params = params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf\n",
    "\n",
    "def xgboost_classifier_predict(clf, X, y):\n",
    "    y_pre = clf.predict(X)\n",
    "    print(\"正确率：{}\".format(accuracy_score(y, y_pre)))\n",
    "    print(\"分类结果报告：\\n\", classification_report(y,y_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:23:31] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { params } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\n",
      "/*******训练集实验结果**********/\n",
      "正确率：0.9798994974874372\n",
      "分类结果报告：\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     23020\n",
      "           1       0.99      0.78      0.88      2335\n",
      "           2       1.00      0.97      0.99       629\n",
      "           3       1.00      1.00      1.00       284\n",
      "\n",
      "    accuracy                           0.98     26268\n",
      "   macro avg       0.99      0.94      0.96     26268\n",
      "weighted avg       0.98      0.98      0.98     26268\n",
      "\n",
      "\n",
      "/*******验证集实验结果**********/\n",
      "正确率：0.8861485135315291\n",
      "分类结果报告：\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      6468\n",
      "           1       0.55      0.31      0.39       749\n",
      "           2       0.40      0.15      0.22       195\n",
      "           3       0.44      0.16      0.23        89\n",
      "\n",
      "    accuracy                           0.89      7501\n",
      "   macro avg       0.58      0.40      0.45      7501\n",
      "weighted avg       0.86      0.89      0.87      7501\n",
      "\n",
      "\n",
      "/*******测试集实验结果**********/\n",
      "正确率：0.9239594450373533\n",
      "分类结果报告：\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97      3435\n",
      "           1       0.49      0.33      0.40       243\n",
      "           2       0.39      0.14      0.20        51\n",
      "           3       0.11      0.05      0.07        19\n",
      "\n",
      "    accuracy                           0.92      3748\n",
      "   macro avg       0.48      0.38      0.41      3748\n",
      "weighted avg       0.91      0.92      0.91      3748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main_xgboost(path):\n",
    "    T = 6\n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test = preprocess_xgboost(path, T)\n",
    "    \n",
    "    params = {'max_depth':5, \n",
    "         'learning_rate':0.01,\n",
    "         'n_estimators':500,\n",
    "         'booster':'gbtree', \n",
    "         'nthread':-1,\n",
    "         'gamma':0.1,\n",
    "         'subsample':0.8,\n",
    "         'colsample_bytree':0.7,\n",
    "         'colsample_bylevel':1,\n",
    "         'silent':False, \n",
    "         'reg_alpha':0,\n",
    "         'reg_lambda':1,\n",
    "         'min_child_weight':1,\n",
    "         'scale_pos_weight':1,\n",
    "         'objective':'multi:softmax',\n",
    "         'num_class':5}\n",
    "    xgb_clf = xgboost_classifier_train(params, X_train, y_train)\n",
    "    \n",
    "    print('\\n/*******训练集实验结果**********/')\n",
    "    xgboost_classifier_predict(xgb_clf, X_train, y_train)\n",
    "    \n",
    "    print('\\n/*******验证集实验结果**********/')\n",
    "    xgboost_classifier_predict(xgb_clf, X_valid, y_valid)\n",
    "    \n",
    "    print('\\n/*******测试集实验结果**********/')\n",
    "    xgboost_classifier_predict(xgb_clf, X_test, y_test)\n",
    "   \n",
    "path = 'hourly-weather-surface/station_385_small.csv'\n",
    "main_xgboost(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM实现时间序列数据的预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM网络\n",
    "class LSTM_Classifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(LSTM_Classifier, self).__init__()\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers)\n",
    "        self.f = nn.Sequential(nn.Linear(hidden_size, output_size), \n",
    "                               nn.Softmax())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        output, _ = self.rnn(x)\n",
    "        seq_len, batch, hidden_size = output.shape\n",
    "        output = self.f(output[-1,:,:].view(-1, hidden_size))\n",
    "        return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_train(X_train, y_train, X_valid, y_valid):\n",
    "    #数据格式处理\n",
    "    n_train, t, p = X_train.shape\n",
    "    n_valid = X_valid.shape[0]\n",
    "    X_train = X_train.reshape(-1,n_train,p)\n",
    "    X_valid = X_valid.reshape(-1,n_valid,p)\n",
    "    \n",
    "    #转为张量\n",
    "    X_train = torch.from_numpy(X_train).double()\n",
    "    y_train = torch.from_numpy(y_train) \n",
    "   \n",
    "    X_valid = torch.from_numpy(X_valid).double()\n",
    "    y_valid = torch.from_numpy(y_valid) \n",
    "    \n",
    "    model = LSTM_Classifier(input_size = p, hidden_size = 20, output_size = 4, num_layers=2)\n",
    "    print(model)\n",
    "    Loss = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1, momentum = 0.5)\n",
    "\n",
    "    \n",
    "    for i in range(100):\n",
    "        model.zero_grad() #梯度清零\n",
    "        var_X = Variable(X_train)#.type(torch.FloatTensor)\n",
    "        var_y = Variable(y_train)#.type(torch.FloatTensor)\n",
    "        out = model(var_X)\n",
    "        #print(out.shape, var_y.shape)\n",
    "        loss = Loss(out, var_y.long().squeeze())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1)%50 ==0:\n",
    "            print('Epoch: {}, Loss: {:.5f}'.format(i+1, loss.item()))\n",
    "        '''\n",
    "            var_X_valid = Variable(X_valid)\n",
    "            var_y_valid = Variable(y_valid)\n",
    "            pre_y = model(var_X_valid).data.max()\n",
    "        '''\n",
    "    return model\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_predict(model, X, y):\n",
    "    n, t, p = X.shape\n",
    "    X = X.reshape(-1,n,p)\n",
    "    X = torch.from_numpy(X).double()\n",
    "    var_X = Variable(X)\n",
    "    output = model(var_X)\n",
    "    y_pre = output.data.max(dim=1)[1]\n",
    "    y_pre = y_pre.numpy()\n",
    "    print(\"正确率：{}\".format(accuracy_score(y, y_pre)))\n",
    "    print(\"分类结果报告：\\n\", classification_report(y,y_pre))\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26268, 6, 13)\n",
      "LSTM_Classifier(\n",
      "  (rnn): LSTM(13, 20, num_layers=2)\n",
      "  (f): Sequential(\n",
      "    (0): Linear(in_features=20, out_features=4, bias=True)\n",
      "    (1): Softmax(dim=None)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50, Loss: 0.89964\n",
      "Epoch: 100, Loss: 0.87700\n"
     ]
    }
   ],
   "source": [
    "T = 6\n",
    "path = 'hourly-weather-surface/station_385_small.csv'\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test = load_data(path, T)\n",
    "print(X_train.shape)\n",
    "model = lstm_train(X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正确率：0.862285028662845\n",
      "分类结果报告：\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93      6468\n",
      "           1       0.00      0.00      0.00       749\n",
      "           2       0.00      0.00      0.00       195\n",
      "           3       0.00      0.00      0.00        89\n",
      "\n",
      "    accuracy                           0.86      7501\n",
      "   macro avg       0.22      0.25      0.23      7501\n",
      "weighted avg       0.74      0.86      0.80      7501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pre_y = lstm_predict(model, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7501, 4])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.9804, 0.9804, 0.9804,  ..., 0.9804, 0.9804, 0.9811]),\n",
       "indices=tensor([0, 0, 0,  ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_y.data.max(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_y = pre_y.data.max(dim=1)[1]\n",
    "pre_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.862285028662845"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pre_y.numpy() == y_valid)/len(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93      6468\n",
      "           1       0.00      0.00      0.00       749\n",
      "           2       0.00      0.00      0.00       195\n",
      "           3       0.00      0.00      0.00        89\n",
      "\n",
      "    accuracy                           0.86      7501\n",
      "   macro avg       0.22      0.25      0.23      7501\n",
      "weighted avg       0.74      0.86      0.80      7501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid ,pre_y.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
