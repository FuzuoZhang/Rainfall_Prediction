{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datatrans(data, T):\n",
    "    n, p = data.shape\n",
    "    n_sample = n - T\n",
    "    newdata = np.zeros((n_sample, T, p))\n",
    "    target = np.zeros((n_sample,))\n",
    "    for i in range(n_sample):\n",
    "        newdata[i] = data.iloc[i:i + T]\n",
    "        target[i] = data.iloc[i + T, 12]\n",
    "    return newdata, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value2class(y):\n",
    "    y[np.where((y > 0) & (y <= 1))] = 1\n",
    "    y[np.where((y > 1) & (y <= 4))] = 2\n",
    "    y[np.where(y > 4)] = 3\n",
    "    #y[np.where((y > 4) & (y <= 16))] = 3\n",
    "    return y.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    data = pd.read_csv(path)\n",
    "    # data = data.drop('Unnamed: 0')\n",
    "\n",
    "    N = data.shape[0]\n",
    "    n_train = round(N * 0.7)\n",
    "    n_valid = round(N * 0.2)\n",
    "    n_test = N - n_train - n_valid\n",
    "\n",
    "    train = data.iloc[:n_train]\n",
    "    valid = data.iloc[n_train:n_train + n_valid]\n",
    "    test = data.iloc[n_train + n_valid:]\n",
    "\n",
    "    X_train, y_train = datatrans(train, T=6)\n",
    "    X_valid, y_valid = datatrans(valid, T=6)\n",
    "    X_test, y_test = datatrans(test, T=6)\n",
    "\n",
    "    # 展开\n",
    "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_valid = X_valid.reshape(X_valid.shape[0],-1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "    # 分类\n",
    "    y_train = value2class(y_train)\n",
    "    y_valid = value2class(y_valid)\n",
    "    y_test = value2class(y_test)\n",
    "\n",
    "    # normalization\n",
    "    sr_X = StandardScaler()\n",
    "    X_train = sr_X.fit_transform(X_train)\n",
    "    X_valid = sr_X.fit_transform(X_valid)\n",
    "    X_test = sr_X.fit_transform(X_test)\n",
    "\n",
    "    return X_train, y_train, X_valid, y_valid, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = load_data('/Users/melody618/Desktop/大作业/降水量预测/code/station_385_small_a.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train score: 0.885107354957\n",
      "The valid score: 0.868550859885\n",
      "The test score: 0.922892209178\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.99      0.96      3435\n",
      "          1       0.51      0.16      0.24       243\n",
      "          2       0.42      0.10      0.16        51\n",
      "          3       0.11      0.05      0.07        19\n",
      "\n",
      "avg / total       0.90      0.92      0.90      3748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_result = lr.predict(X_test)\n",
    "    \n",
    "print(\"The train score:\", lr.score(X_train, y_train))\n",
    "print(\"The valid score:\", lr.score(X_valid, y_valid))\n",
    "print(\"The test score:\", lr.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train score: 0.867100654789\n",
      "The valid score: 0.854552726303\n",
      "The test score: 0.882337246531\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.93      0.95      3435\n",
      "          1       0.36      0.32      0.34       243\n",
      "          2       0.19      0.37      0.25        51\n",
      "          3       0.06      0.26      0.10        19\n",
      "\n",
      "avg / total       0.90      0.88      0.89      3748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000, class_weight='balanced') # classweight 按照样本数比例生成权重，解决样本不均衡问题\n",
    "lr.fit(X_train, y_train)\n",
    "y_result = lr.predict(X_test)\n",
    "    \n",
    "print(\"The train score:\", lr.score(X_train, y_train))\n",
    "print(\"The valid score:\", lr.score(X_valid, y_valid))\n",
    "print(\"The test score:\", lr.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train score: 0.876351454241\n",
      "The valid score: 0.855885881882\n",
      "The test score: 0.887673425827\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.95      0.95      3435\n",
      "          1       0.23      0.13      0.17       243\n",
      "          2       0.13      0.20      0.16        51\n",
      "          3       0.11      0.26      0.16        19\n",
      "\n",
      "avg / total       0.88      0.89      0.88      3748\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/python3.6/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "sgdc = SGDClassifier()\n",
    "sgdc.fit(X_train, y_train)\n",
    "y_result = sgdc.predict(X_test)\n",
    "    \n",
    "print(\"The train score:\", sgdc.score(X_train, y_train))\n",
    "print(\"The valid score:\", sgdc.score(X_valid, y_valid))\n",
    "print(\"The test score:\", sgdc.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train score: 0.719430485762\n",
      "The valid score: 0.714171443807\n",
      "The test score: 0.714247598719\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.76      0.84      3435\n",
      "          1       0.07      0.19      0.10       243\n",
      "          2       0.10      0.39      0.15        51\n",
      "          3       0.10      0.53      0.17        19\n",
      "\n",
      "avg / total       0.88      0.71      0.78      3748\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/python3.6/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "sgdc = SGDClassifier(class_weight='balanced')\n",
    "sgdc.fit(X_train, y_train)\n",
    "y_result = sgdc.predict(X_test)\n",
    "    \n",
    "print(\"The train score:\", sgdc.score(X_train, y_train))\n",
    "print(\"The valid score:\", sgdc.score(X_valid, y_valid))\n",
    "print(\"The test score:\", sgdc.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train score: 0.901477082382\n",
      "The valid score: 0.871617117718\n",
      "The test score: 0.926627534685\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.99      0.96      3435\n",
      "          1       0.57      0.22      0.32       243\n",
      "          2       0.58      0.14      0.22        51\n",
      "          3       0.29      0.11      0.15        19\n",
      "\n",
      "avg / total       0.91      0.93      0.91      3748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "y_result = svc.predict(X_test)\n",
    "    \n",
    "print(\"The train score:\", svc.score(X_train, y_train))\n",
    "print(\"The valid score:\", svc.score(X_valid, y_valid))\n",
    "print(\"The test score:\", svc.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train score: 0.800137048881\n",
      "The valid score: 0.760165311292\n",
      "The test score: 0.716115261473\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.73      0.84      3435\n",
      "          1       0.17      0.63      0.27       243\n",
      "          2       0.09      0.35      0.15        51\n",
      "          3       0.03      0.11      0.04        19\n",
      "\n",
      "avg / total       0.91      0.72      0.79      3748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(class_weight='balanced')\n",
    "svc.fit(X_train, y_train)\n",
    "y_result = svc.predict(X_test)\n",
    "    \n",
    "print(\"The train score:\", svc.score(X_train, y_train))\n",
    "print(\"The valid score:\", svc.score(X_valid, y_valid))\n",
    "print(\"The test score:\", svc.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train score: 0.938480280189\n",
      "The valid score: 0.873483535529\n",
      "The test score: 0.919423692636\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.98      0.96      3435\n",
      "          1       0.45      0.24      0.32       243\n",
      "          2       0.34      0.22      0.27        51\n",
      "          3       0.25      0.05      0.09        19\n",
      "\n",
      "avg / total       0.90      0.92      0.91      3748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=10)\n",
    "svc.fit(X_train, y_train)\n",
    "y_result = svc.predict(X_test)\n",
    "    \n",
    "print(\"The train score:\", svc.score(X_train, y_train))\n",
    "print(\"The valid score:\", svc.score(X_valid, y_valid))\n",
    "print(\"The test score:\", svc.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train score: 0.88750571037\n",
      "The valid score: 0.797626983069\n",
      "The test score: 0.783351120598\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.81      0.88      3435\n",
      "          1       0.19      0.58      0.29       243\n",
      "          2       0.12      0.22      0.15        51\n",
      "          3       0.00      0.00      0.00        19\n",
      "\n",
      "avg / total       0.90      0.78      0.83      3748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=10,class_weight='balanced')\n",
    "svc.fit(X_train, y_train)\n",
    "y_result = svc.predict(X_test)\n",
    "    \n",
    "print(\"The train score:\", svc.score(X_train, y_train))\n",
    "print(\"The valid score:\", svc.score(X_valid, y_valid))\n",
    "print(\"The test score:\", svc.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train score: 0.906654484544\n",
      "The valid score: 0.856419144114\n",
      "The test score: 0.905016008538\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.97      0.95      3435\n",
      "          1       0.28      0.15      0.20       243\n",
      "          2       0.27      0.12      0.16        51\n",
      "          3       0.00      0.00      0.00        19\n",
      "\n",
      "avg / total       0.88      0.91      0.89      3748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_result = knn.predict(X_test)\n",
    "\n",
    "print(\"The train score:\", knn.score(X_train, y_train))\n",
    "print(\"The valid score:\", knn.score(X_valid, y_valid))\n",
    "print(\"The test score:\", knn.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train score: 0.894320085275\n",
      "The valid score: 0.865217970937\n",
      "The test score: 0.913020277481\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.99      0.96      3435\n",
      "          1       0.32      0.10      0.16       243\n",
      "          2       0.17      0.04      0.06        51\n",
      "          3       0.17      0.05      0.08        19\n",
      "\n",
      "avg / total       0.88      0.91      0.89      3748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=10) # default = 5\n",
    "knn.fit(X_train, y_train)\n",
    "y_result = knn.predict(X_test)\n",
    "\n",
    "print(\"The train score:\", knn.score(X_train, y_train))\n",
    "print(\"The valid score:\", knn.score(X_valid, y_valid))\n",
    "print(\"The test score:\", knn.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train score: 0.927820922796\n",
      "The valid score: 0.876416477803\n",
      "The test score: 0.900480256137\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.96      0.95      3435\n",
      "          1       0.33      0.32      0.32       243\n",
      "          2       0.36      0.31      0.33        51\n",
      "          3       0.00      0.00      0.00        19\n",
      "\n",
      "avg / total       0.90      0.90      0.90      3748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=10)\n",
    "dtc.fit(X_train, y_train)\n",
    "y_result = dtc.predict(X_test)\n",
    "    \n",
    "print(\"The train score:\", dtc.score(X_train, y_train))\n",
    "print(\"The valid score:\", dtc.score(X_valid, y_valid))\n",
    "print(\"The test score:\", dtc.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train score: 0.750380691335\n",
      "The valid score: 0.704306092521\n",
      "The test score: 0.726520811099\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.75      0.85      3435\n",
      "          1       0.18      0.53      0.27       243\n",
      "          2       0.06      0.35      0.10        51\n",
      "          3       0.04      0.21      0.06        19\n",
      "\n",
      "avg / total       0.91      0.73      0.80      3748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=10, class_weight='balanced')\n",
    "dtc.fit(X_train, y_train)\n",
    "y_result = dtc.predict(X_test)\n",
    "    \n",
    "print(\"The train score:\", dtc.score(X_train, y_train))\n",
    "print(\"The valid score:\", dtc.score(X_valid, y_valid))\n",
    "print(\"The test score:\", dtc.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train score: 1.0\n",
      "The valid score: 0.826023196907\n",
      "The test score: 0.853521878335\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.91      0.93      3435\n",
      "          1       0.20      0.27      0.23       243\n",
      "          2       0.11      0.20      0.14        51\n",
      "          3       0.03      0.05      0.03        19\n",
      "\n",
      "avg / total       0.89      0.85      0.87      3748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(class_weight='balanced')\n",
    "dtc.fit(X_train, y_train)\n",
    "y_result = dtc.predict(X_test)\n",
    "    \n",
    "print(\"The train score:\", dtc.score(X_train, y_train))\n",
    "print(\"The valid score:\", dtc.score(X_valid, y_valid))\n",
    "print(\"The test score:\", dtc.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train score: 0.897099132024\n",
      "The valid score: 0.885215304626\n",
      "The test score: 0.921824973319\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.97      3435\n",
      "          1       0.49      0.26      0.34       243\n",
      "          2       0.29      0.35      0.32        51\n",
      "          3       0.15      0.11      0.12        19\n",
      "\n",
      "avg / total       0.91      0.92      0.91      3748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(10,5), max_iter=500)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_result = mlp.predict(X_test)\n",
    "    \n",
    "print(\"The train score:\", mlp.score(X_train, y_train))\n",
    "print(\"The valid score:\", mlp.score(X_valid, y_valid))\n",
    "print(\"The test score:\", mlp.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train score: 0.898050860362\n",
      "The valid score: 0.882948940141\n",
      "The test score: 0.918623265742\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.96      3435\n",
      "          1       0.43      0.28      0.34       243\n",
      "          2       0.31      0.37      0.34        51\n",
      "          3       0.00      0.00      0.00        19\n",
      "\n",
      "avg / total       0.90      0.92      0.91      3748\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/python3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(10,20,5), max_iter=500)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_result = mlp.predict(X_test)\n",
    "    \n",
    "print(\"The train score:\", mlp.score(X_train, y_train))\n",
    "print(\"The valid score:\", mlp.score(X_valid, y_valid))\n",
    "print(\"The test score:\", mlp.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
